#!/usr/bin/env python3
"""
MLflow Docker ì´ë¯¸ì§€ ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸
ì‚¬ìš©ë²•: python build_mlflow.py
"""
import mlflow
import os

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
MLFLOW_TRACKING_URI = os.getenv("MLFLOW_TRACKING_URI", "http://localhost:5000")
mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)

# ëª¨ë¸ ID ì„¤ì •
MODEL_ID = os.getenv("MLFLOW_MODEL_ID", "lgbm_classifier")
MODEL_STAGE = os.getenv("MLFLOW_MODEL_STAGE", "latest")  # latest, production ë“±

model_uri = f"models:/{MODEL_ID}/{MODEL_STAGE}"
image_name = f"restaurant-predictor-{MODEL_ID}:{MODEL_STAGE}"

print(f"ğŸš€ Building Docker image for model: {model_uri}")
print(f"   Image name: {image_name}")

# Docker ì´ë¯¸ì§€ ë¹Œë“œ (MLServer ë¯¸ì‚¬ìš© - Docker Compose í™˜ê²½ìš©)
mlflow.models.build_docker(
    model_uri=model_uri,
    name=image_name,
    enable_mlserver=False  # MLServer ì‚¬ìš© ì•ˆ í•¨ (Docker Compose í™˜ê²½)
)

print(f"âœ… Docker image built: {image_name}")
print(f"\nì‚¬ìš©ë²•:")
print(f"  docker run -p 5001:8080 {image_name}")

